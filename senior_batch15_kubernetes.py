"""
SENIOR AI ENGINEER INTERVIEW PREP - BATCH 15: KUBERNETES FOR ML/AI
===================================================================
20 Senior-Level Kubernetes questions for ML/AI workloads
"""

def create_question(question_text, options, correct_index, explanation, difficulty, time_seconds):
    return {"question": question_text, "options": options, "correct_answer": correct_index,
            "explanation": explanation, "difficulty": difficulty, "estimated_time": time_seconds}

def populate_senior_kubernetes():
    return [
        create_question("Q1: PyTorch training crashes with 'No space left' but disk has 500GB free. num_workers=16. Issue?", ["Increase PVC", "Missing shm volume (emptyDir medium=Memory sizeLimit=32Gi). Default 64MB too small for DataLoader", "Reduce workers", "hostPath"], 1, "DataLoader uses /dev/shm. K8s default 64MB insufficient. Mount emptyDir with medium=Memory, sizeLimit=32Gi.", "Hard", 200),
        create_question("Q2: Inference pod has limits.memory=16Gi but no requests. Scheduling unpredictable. Fix?", ["Add more nodes", "Set requests=limits for Guaranteed QoS. Scheduler uses requests for placement decisions", "Lower priority", "Wrong namespace"], 1, "K8s uses requests for scheduling. Without requests, scheduler doesn't reserve resources. Set requests=limits for Guaranteed QoS.", "Hard", 200),
        create_question("Q3: Cluster has A100 and V100 nodes. 70B model needs A100 only. How to ensure scheduling?", ["nodeSelector gpu-type=a100", "nodeAffinity requiredDuringScheduling with gpu-type=a100 labels. Hard constraint ensures A100 only", "Taints on V100", "Specify nodeName"], 1, "nodeAffinity with required constraint ensures pod only schedules on A100 nodes. Label nodes by GPU type.", "Hard", 210),
        create_question("Q4: Training saves 140GB checkpoints. emptyDir loses data on pod restart. Need persistent shared storage. Solution?", ["hostPath", "PersistentVolumeClaim with ReadWriteMany (NFS/EFS). Survives restarts, accessible from multiple pods", "ConfigMap", "S3 in shutdown hook"], 1, "PVC with RWX access mode (NFS/EFS backend) provides durable storage shared across pods. Survives restarts.", "Hard", 200),
        create_question("Q5: Inference deployment has 5 replicas. Queue reaches 1000, p99 latency 5sec. Want autoscaling on queue depth. Setup?", ["CPU-based HPA", "Prometheus + custom metrics API + HPA targeting queue depth 50/pod. Scales before latency degrades", "Manual scaling", "Cluster Autoscaler"], 1, "HPA with custom metrics (queue depth, GPU util) scales pods. Set target to scale proactively before SLA breach.", "Hard", 210),
        create_question("Q6: A100 GPUs underutilized. Small inference needs 5GB but GPU has 40GB. How to share GPUs?", ["Time-slicing", "MIG (Multi-Instance GPU) partitions A100 into 7x 5GB slices. Hardware isolation, 7x capacity", "CUDA_VISIBLE_DEVICES", "Fractional GPUs"], 1, "MIG creates hardware-isolated GPU slices. 1g.5gb profile gives 7 instances per A100. Request nvidia.com/mig-1g.5gb.", "Hard", 200),
        create_question("Q7: GPU nodes expensive. Want to reserve for ML workloads only, block system pods. How?", ["nodeSelector", "Taint GPU nodes with gpu=true:NoSchedule. Only pods with matching toleration can schedule", "Resource requests", "PodSecurityPolicy"], 1, "Taints repel pods without tolerations. Taint GPU nodes, add tolerations to ML pods only. Prevents waste.", "Hard", 190),
        create_question("Q8: Inference pods take 5min to start (30GB model download). 20 replicas = 600GB traffic. Optimize?", ["Bake into image", "Init container downloads to shared PVC once. Main container uses cached model. 30GB vs 600GB", "Sidecar", "Entrypoint script"], 1, "Init container runs before main. First pod downloads to PVC, others skip (check .downloaded marker). Massive savings.", "Hard", 200),
        create_question("Q9: Need one-time 48hr training job. Use Deployment or Job?", ["Deployment", "Job with completions=1, restartPolicy=OnFailure. Runs to completion, doesn't restart after success", "StatefulSet", "DaemonSet"], 1, "Job for batch workloads that run to completion. Deployment for long-running services (inference).", "Hard", 170),
        create_question("Q10: Want to change training hyperparameters without rebuilding image. How to externalize?", ["Hardcode in Dockerfile", "ConfigMap mounted as volume or env vars. Update ConfigMap, restart pods with new config", "Command args in spec", "Secrets"], 1, "ConfigMaps store non-sensitive config. Mount as files or inject as env vars. Update without rebuilds.", "Hard", 170),
        create_question("Q11: Pods need HuggingFace token. Where to store?", ["Env var in YAML", "Secret (kubectl create secret generic). Mount as env or volume. Encrypted at rest", "Hardcode", "ConfigMap"], 1, "Secrets for sensitive data (tokens, passwords). Base64-encoded, optionally encrypted. Never use ConfigMaps for secrets.", "Hard", 160),
        create_question("Q12: Multi-team cluster. Limit Team A to 16 GPUs max. How?", ["Namespace quotas", "ResourceQuota in namespace: limits.nvidia.com/gpu=16. Prevents team from exceeding quota", "Manual tracking", "RBAC"], 1, "ResourceQuota limits total resource consumption per namespace. Essential for multi-tenant clusters.", "Hard", 160),
        create_question("Q13: Isolate training namespace from inference namespace traffic. How?", ["Different clusters", "NetworkPolicy: deny ingress from training namespace to inference. L3/L4 firewall", "Service accounts", "Subnets"], 1, "NetworkPolicy controls pod-to-pod traffic. Default allow-all. Create policies for zero-trust isolation.", "Hard", 170),
        create_question("Q14: Need distributed tracing across 5 microservices. How?", ["Manual logging", "Istio service mesh. Sidecar proxies provide automatic tracing with Jaeger/Zipkin", "Prometheus", "SSH to pods"], 1, "Service mesh (Istio/Linkerd) provides observability, security (mTLS), traffic management via sidecar proxies.", "Hard", 180),
        create_question("Q15: During cluster upgrade, nodes drain and kill inference pods. Need 80% available. How?", ["Disable upgrades", "PodDisruptionBudget minAvailable=80%. Limits voluntary disruptions during maintenance", "More replicas", "DaemonSet"], 1, "PDB prevents operations (drain, eviction) from breaking SLAs. Set minAvailable or maxUnavailable.", "Hard", 170),
        create_question("Q16: Cluster full. Low-priority training should yield to high-priority inference. How?", ["Manual deletion", "PriorityClass (inference=1000, training=100). Scheduler preempts lower-priority pods for higher", "Namespaces", "Add nodes"], 1, "PriorityClass enables preemption. Higher-priority pods can evict lower-priority when resources scarce.", "Hard", 170),
        create_question("Q17: ML engineers need Job permissions in ml-training namespace only, not production. How?", ["cluster-admin", "Role in ml-training namespace with Job verbs, bind with RoleBinding. Namespace-scoped RBAC", "NodeSelector", "Separate cluster"], 1, "RBAC: Role (namespace permissions) + RoleBinding (assign to users). Principle of least privilege.", "Hard", 180),
        create_question("Q18: Training needs 10 GPUs but cluster has 8. Pods pending. Want auto-add nodes. How?", ["Manual provision", "Cluster Autoscaler. Detects unschedulable pods, adds nodes to pool automatically", "HPA", "Wait"], 1, "Cluster Autoscaler scales node count. Scales up when pods pending, down when nodes idle >10min.", "Hard", 180),
        create_question("Q19: Training expensive on on-demand ($30/hr). Fault-tolerant (checkpointing). Reduce cost 70%?", ["Smaller GPUs", "Spot/preemptible instances. 60-90% cheaper. Checkpoint frequently to tolerate interruptions", "Reduce batch", "Train less"], 1, "Spot instances save 60-90% but can be terminated. Perfect for checkpointed training. Use taints for critical workloads.", "Hard", 170),
        create_question("Q20: Need to monitor GPU utilization, temperature, memory for all pods. How?", ["SSH + nvidia-smi", "DCGM Exporter DaemonSet. Scrapes GPU metrics, exposes to Prometheus. Visualize in Grafana", "kubectl top", "Cloud console"], 1, "NVIDIA DCGM Exporter exposes GPU metrics in Prometheus format. Deploy as DaemonSet on GPU nodes.", "Hard", 180),
    ]

if __name__ == "__main__":
    print(f"Generated {len(populate_senior_kubernetes())} K8s questions")
